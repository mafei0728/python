#  3-1 字符编码

提起字符编码,我们先搞清楚什么是编码和解码

编码的意思是将Unicode字符按照编码规则（如UTF-8）编成字节序列： 

```shell
2.7
>>> a=u'马飞'
>>> a.encode('gbk')
'\xc2\xed\xb7\xc9'
3.x
>>> a='马飞'
>>> a.encode('gbk')
b'\xc2\xed\xb7\xc9
```

对应的，解码就是将字节序列按照编码规则（如UTF-8）解释成unicode形式。 

Python有两种不同的字符串，一种存储文本(str,unicode)，一种存储字节(bytes)。对于文本，Python内部采用Unicode存储，而字节字符串显示原始字节序列或者ASCII 

python2中不指定抬头是asicc,指定了就是按指定的来算,比如windows默认的cmd就是gbk

python3不用指定,默认就是unicode

如果我们想要将台湾的big5转换成gbk

big5-----decode解码----unicode------encode编码------gbk

关于字节

asicll 1个字节

gbk 2个字节

utf-8 中文3个字节

unicode(utf-16)2个字节

先说明一个问题,python解释器会自动将unicode转换为当前指定的字符集,比如你指定了utf-8,就会自动转存utf8

也就是任何环境下decode成unicode在python中都会正常打印.所以一般encode成16进制来传输

## 2.x

在python 2中默认编码是ascii,可以加u指定为unicode

```shell
#!/usr/bin/env python
# -*- coding:utf-8 -*-
a = u"马飞"
print(a) 
print a.encode("gbk") //如果指定为unicoede就只有编码了

#!/usr/bin/env python
# -*- coding:utf-8 -*-
a = "马飞"
print(a)
print(a.decode("utf-8")).encode("gbk") // 转换成gbk

#在py3里面就不用指定抬头了,默认是就是unicode,只有编码
#!/usr/bin/env python
a = "马飞"
print(a.encode('gbk'))
print(a.encode("utf8"))

#!/usr/bin/env python
# -*- coding:utf-8 -*-
a = "马飞"
print(len(a.encode("utf8")))
print(len(a))
print(len(a.encode("gbk")))
6
2   // 只有unicode按字符算,其他的按字节算
4
```



![mark](http://otu09lzop.bkt.clouddn.com/typora-photo/180805/7BcEa2A5I0.png?imageslim)

* ```python
  #获取系统字符编码
  import sys
  print(sys.getdefaultencoding())
  ```

* ```python
  #在python2.X在做字符编码的转换
  #-*- coding:utf-8 -*-
  import sys
  print(sys.getdefaultencoding())
  _a = "你好,马飞"
  s_to_unicode = _a.decode("utf8")
  print(s_to_unicode)
  print(s_to_unicode,type(s_to_unicode))
  ```

* 总结2.x

  * unicode 可以直接在utf8中打印
  * GBK和unicode无法互相打印,需要解码,转码
  * 所有的decode()都是解码成unicode的过程,必须声明之前的编码
  * encode()编码过程必须声明
  * 2.x默认编码是ascii,如果没指定的话

  ## 3.x

  ```python
  
  b'\xc2\xed\xb7\xc9'
  b'\xe9\xa9\xac\xe9\xa3\x9e'
  b'\xe9\xa9\xac\xe9\xa3\x9e'
  ```
  ![mark](http://otu09lzop.bkt.clouddn.com/typora-photo/20170825/000149375.png)

* 总结 3.0默认是unicode 起手没有decode(),只有encode()转成bit,然后在转成

  ![mark](http://otu09lzop.bkt.clouddn.com/typora-photo/20170824/225957819.png)

我的理解是PY3中字符串就是unicode ,bytes是字节类型,严格区分

py2中字节类型是str,str对象也是字节类型,很操蛋,,在print的时侯.系统会根据环境编码来进行隐形的解码

```shell
py2:
>>> a='马飞'
>>> a 
'\xc2\xed\xb7\xc9'  // 默认是系统环境的编码gbk
>>> a
'\xc2\xed\xb7\xc9'
>>> print(a) ---- print自动打印成可识别 隐形解码
马飞
>>> print('\xc2\xed\xb7\xc9') 效果一样 2中str 也是字节类型的 
马飞
>>> a.decode('gbk')
u'\u9a6c\u98de'
>>> a.decode('gbk').encode('utf8') 
'\xe9\xa9\xac\xe9\xa3\x9e'
>>> print('\xe9\xa9\xac\xe9\xa3\x9e')  utf出现编码错误
椹
>>> print('\xe9\xa9\xac\xe9\xa3\x9e'.decode('utf8')) unicode自动编码成当前环境中的
马飞
>>> a.decode('gbk') 
u'\u9a6c\u98de'
>>> print(u'\u9a6c\u98de')  // 解释print自动一说,自动且不需要指定
马飞
>>> u'\u9a6c\u98de'  // 2中必须通过print来解决这个	
u'\u9a6c\u98de'
===================================================================================
py3:
>>> a = '马飞'
>>> a
'马飞'
>>> a.decode('utf8') // 默认是unicode不能解码.3中str对象就是unicode文本字符串
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: 'str' object has no attribute 'decode'
>>> a.encode('utf8') 编码
b'\xe9\xa9\xac\xe9\xa3\x9e'
>>> a.encode('gbk') 编码都带b,才是字节类型的字符串
b'\xc2\xed\xb7\xc9'
>>> print('\xc2\xed\xb7\xc9') //去掉b就是unicode,编码错误
Âí·É
>>> print(b'\xc2\xed\xb7\xc9') // 带b的字节类型的字符串,
b'\xc2\xed\xb7\xc9'
>>> print(b'\xc2\xed\xb7\xc9'.decode('gbk')) // 解码成unicode 自动编码成系统当前的编码显示出
马飞
>>> print(u'\u9a6c\u98de') // 解释自动
马飞
>>> a=u'\u9a6c\u98de'
>>> a      // 3中只要你正确编码成 unicode显示是不会乱码的
'马飞'
```

Python2比较操蛋,字符串类型和字节类型一回事,两种存储格式 字节或者unicode.两种类型str和unicode

![mark](http://otu09lzop.bkt.clouddn.com/typora-photo/180815/fB6ibjE0AC.png?imageslim)

Python2比较操蛋,字符串类型和字节类型一回事,两种存储格式 字节或者unicode.两种类型str和unicode

python3 存储bytes和unicode,两种类型bytes和str

将文本字符串编码，转换为已编码的字节字符串类型 

所以说,数据读取到内存其实都是按默认编码格式.py2的抬头,py3和其他语言的unicode.但是数据存在介质就不一定了.根据使用场景来定,用什么编码的bytes存在介质.

我们读取文件到内存的时候,就是解释器把文件decode成unicode的过程,不指定,则默认按解释器的编码来解码

读取到内存中解释器会自动帮我们指定解码的编码,如果自己制定一个错的就会报错

```shell
Traceback (most recent call last):
  File "D:/python_study/testdir/trst1.py", line 4, in <module>
    print(f.readlines())
  File "D:\Python37\lib\codecs.py", line 322, in decode
    (result, consumed) = self._buffer_decode(data, self.errors, final)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc6 in position 0: invalid continuation byte
```

综上所述,我们只需要转到unicode就够了,也不会有乱码了

那我们为什么不直接用unicode存储和传输呢,还要编码成utf8? 因为utf8比unicode省空间,unicode通常占2字节

导致英文也是占了2个字节.utf8是可变长编码.英文还是占多数

bytes是传输和存储用的,unicode是显示用的

为什么内存中要用unicode来储存?

因为unicode相当是一个万国码

![mark](http://otu09lzop.bkt.clouddn.com/typora-photo/180816/Kjh37f79Ij.png?imageslim)

python2中如果不指定,存在内存中默认是按ASCII来解码

python3中如果不指定,存在内存中默认按utf8来解码

如果python3中打开一个gbk格式的文件,一定要在抬头指定 # -*- coding:gbk -*-

http://python.jobbole.com/86578/

http://python.jobbole.com/86578/

http://www.cnblogs.com/yuanchenqi/articles/5956943.html